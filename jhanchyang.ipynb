{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: ['about' 'after' 'again' 'all' 'animal' 'ask' 'baby' 'back' 'bad'\n",
      " 'because' 'bed' 'before' 'big' 'book' 'boy' 'bring' 'brother' 'buy'\n",
      " 'call' 'can' 'car' 'chair' 'child' 'city' 'clothes' 'come' 'computer'\n",
      " 'day' 'dog' 'drink' 'eat' 'family' 'father' 'find' 'first' 'friend' 'get'\n",
      " 'give' 'go' 'good' 'happy' 'have' 'help' 'her' 'home' 'hot' 'how' 'know'\n",
      " 'late' 'leave' 'like' 'make' 'man' 'many' 'me' 'mother' 'name' 'need'\n",
      " 'new' 'no' 'now' 'on' 'one' 'out' 'people' 'play' 'please' 'read' 'right'\n",
      " 'run' 'say' 'school' 'see' 'she' 'sit' 'sleep' 'small' 'sorry' 'stop'\n",
      " 'study' 'take' 'thank you' 'think' 'time' 'today' 'tomorrow' 'want'\n",
      " 'watch' 'we' 'what' 'when' 'where' 'who' 'why' 'work' 'yes' 'you']\n",
      "Label Map: {'about': 0, 'after': 1, 'again': 2, 'all': 3, 'animal': 4, 'ask': 5, 'baby': 6, 'back': 7, 'bad': 8, 'because': 9, 'bed': 10, 'before': 11, 'big': 12, 'book': 13, 'boy': 14, 'bring': 15, 'brother': 16, 'buy': 17, 'call': 18, 'can': 19, 'car': 20, 'chair': 21, 'child': 22, 'city': 23, 'clothes': 24, 'come': 25, 'computer': 26, 'day': 27, 'dog': 28, 'drink': 29, 'eat': 30, 'family': 31, 'father': 32, 'find': 33, 'first': 34, 'friend': 35, 'get': 36, 'give': 37, 'go': 38, 'good': 39, 'happy': 40, 'have': 41, 'help': 42, 'her': 43, 'home': 44, 'hot': 45, 'how': 46, 'know': 47, 'late': 48, 'leave': 49, 'like': 50, 'make': 51, 'man': 52, 'many': 53, 'me': 54, 'mother': 55, 'name': 56, 'need': 57, 'new': 58, 'no': 59, 'now': 60, 'on': 61, 'one': 62, 'out': 63, 'people': 64, 'play': 65, 'please': 66, 'read': 67, 'right': 68, 'run': 69, 'say': 70, 'school': 71, 'see': 72, 'she': 73, 'sit': 74, 'sleep': 75, 'small': 76, 'sorry': 77, 'stop': 78, 'study': 79, 'take': 80, 'thank you': 81, 'think': 82, 'time': 83, 'today': 84, 'tomorrow': 85, 'want': 86, 'watch': 87, 'we': 88, 'what': 89, 'when': 90, 'where': 91, 'who': 92, 'why': 93, 'work': 94, 'yes': 95, 'you': 96}\n",
      "Sequence length distribution: Counter({72: 20, 73: 15, 81: 15, 33: 15, 63: 15, 61: 14, 60: 14, 53: 14, 80: 14, 70: 14, 82: 13, 75: 13, 43: 13, 47: 12, 68: 12, 88: 12, 78: 11, 66: 11, 79: 11, 59: 10, 77: 10, 30: 10, 46: 10, 56: 9, 90: 9, 55: 9, 32: 9, 45: 9, 35: 9, 74: 9, 67: 8, 76: 8, 83: 8, 71: 8, 39: 8, 50: 8, 94: 8, 58: 8, 48: 8, 41: 8, 34: 8, 38: 7, 95: 7, 69: 7, 57: 7, 86: 7, 28: 7, 40: 7, 51: 7, 44: 7, 105: 6, 89: 6, 62: 6, 87: 6, 101: 6, 96: 6, 52: 6, 31: 6, 85: 6, 91: 6, 42: 6, 97: 5, 27: 5, 36: 5, 65: 5, 104: 5, 93: 5, 106: 4, 107: 4, 26: 4, 102: 4, 103: 4, 92: 4, 25: 4, 49: 3, 54: 3, 108: 3, 29: 3, 37: 3, 99: 3, 100: 3, 64: 3, 127: 2, 98: 2, 113: 2, 121: 2, 115: 2, 118: 2, 120: 2, 112: 2, 155: 2, 111: 2, 139: 2, 116: 1, 144: 1, 20: 1, 24: 1, 131: 1, 195: 1, 125: 1, 124: 1, 119: 1, 21: 1, 122: 1, 141: 1, 114: 1, 136: 1, 84: 1, 178: 1, 23: 1, 148: 1, 109: 1, 22: 1})\n",
      "X shape: (702, 10, 1662)\n",
      "y shape: (702, 97)\n",
      "X_train shape: (666, 10, 1662)\n",
      "X_test shape: (36, 10, 1662)\n",
      "y_train shape: (666, 97)\n",
      "y_test shape: (36, 97)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Define the path where your keypoint data is stored\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "\n",
    "# Get the list of actions (labels)\n",
    "actions = np.array(os.listdir(DATA_PATH))\n",
    "print(f\"Actions: {actions}\")\n",
    "\n",
    "# Create a label map\n",
    "label_map = {label: num for num, label in enumerate(actions)}\n",
    "print(f\"Label Map: {label_map}\")\n",
    "\n",
    "# Initialize sequences and labels\n",
    "sequences, labels = [], []\n",
    "\n",
    "# Sequence length (number of frames per video)\n",
    "# Adjust as needed based on your data analysis\n",
    "sequence_length = 10\n",
    "\n",
    "# Collect sequence lengths for analysis\n",
    "sequence_lengths = []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    sequences_dirs = os.listdir(action_path)\n",
    "    for sequence in sequences_dirs:\n",
    "        window = []\n",
    "        sequence_path = os.path.join(action_path, sequence)\n",
    "        frame_files = os.listdir(sequence_path)\n",
    "        frame_files = sorted(frame_files, key=lambda x: int(os.path.splitext(x)[0]))\n",
    "        for frame_file in frame_files:\n",
    "            res = np.load(os.path.join(sequence_path, frame_file))\n",
    "            window.append(res)\n",
    "        sequence_lengths.append(len(window))\n",
    "        \n",
    "        # Pad or truncate sequences to the desired length\n",
    "        if len(window) < sequence_length:\n",
    "            # Pad with zeros\n",
    "            padding = [np.zeros_like(window[0])]*(sequence_length - len(window))\n",
    "            window.extend(padding)\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "        elif len(window) > sequence_length:\n",
    "            # Truncate the sequence\n",
    "            window = window[:sequence_length]\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "        else:\n",
    "            sequences.append(window)\n",
    "            labels.append(label_map[action])\n",
    "\n",
    "# Analyze sequence lengths\n",
    "from collections import Counter\n",
    "print(\"Sequence length distribution:\", Counter(sequence_lengths))\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Rest of your code remains the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/500\n",
      "17/17 [==============================] - 5s 104ms/step - loss: 12.0155 - categorical_accuracy: 0.0075 - val_loss: 10.7919 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 10.2707 - categorical_accuracy: 0.0094 - val_loss: 9.5530 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 9.2667 - categorical_accuracy: 0.0094 - val_loss: 8.8348 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 8.6072 - categorical_accuracy: 0.0188 - val_loss: 8.3391 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 1s 81ms/step - loss: 8.1462 - categorical_accuracy: 0.0169 - val_loss: 7.9489 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 7.7876 - categorical_accuracy: 0.0132 - val_loss: 7.6239 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 7.4739 - categorical_accuracy: 0.0169 - val_loss: 7.3381 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 7.1932 - categorical_accuracy: 0.0188 - val_loss: 7.0907 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 6.9461 - categorical_accuracy: 0.0207 - val_loss: 6.8760 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 6.7298 - categorical_accuracy: 0.0207 - val_loss: 6.6901 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 6.5697 - categorical_accuracy: 0.0132 - val_loss: 6.5312 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 1s 81ms/step - loss: 6.3891 - categorical_accuracy: 0.0150 - val_loss: 6.3764 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 6.2482 - categorical_accuracy: 0.0169 - val_loss: 6.2427 - val_categorical_accuracy: 0.0299 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 6.0932 - categorical_accuracy: 0.0226 - val_loss: 6.1051 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 5.9625 - categorical_accuracy: 0.0226 - val_loss: 5.9913 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 5.8325 - categorical_accuracy: 0.0169 - val_loss: 5.8788 - val_categorical_accuracy: 0.0299 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 5.7211 - categorical_accuracy: 0.0188 - val_loss: 5.8402 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 5.6406 - categorical_accuracy: 0.0244 - val_loss: 5.6864 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 5.5343 - categorical_accuracy: 0.0263 - val_loss: 5.6274 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 5.4469 - categorical_accuracy: 0.0244 - val_loss: 5.5920 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 5.3676 - categorical_accuracy: 0.0244 - val_loss: 5.4776 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 5.3197 - categorical_accuracy: 0.0226 - val_loss: 5.4234 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 5.2124 - categorical_accuracy: 0.0489 - val_loss: 5.3919 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 5.1564 - categorical_accuracy: 0.0301 - val_loss: 5.3604 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 5.1157 - categorical_accuracy: 0.0169 - val_loss: 5.3459 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 5.0288 - categorical_accuracy: 0.0282 - val_loss: 5.2961 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 4.9962 - categorical_accuracy: 0.0301 - val_loss: 5.2370 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 4.9253 - categorical_accuracy: 0.0301 - val_loss: 5.1625 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 4.8790 - categorical_accuracy: 0.0244 - val_loss: 5.2085 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 4.8204 - categorical_accuracy: 0.0263 - val_loss: 6.1054 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 4.8145 - categorical_accuracy: 0.0338 - val_loss: 5.1364 - val_categorical_accuracy: 0.0299 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 1s 81ms/step - loss: 4.8003 - categorical_accuracy: 0.0320 - val_loss: 45.4099 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 4.8245 - categorical_accuracy: 0.0188 - val_loss: 12.5875 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 4.7599 - categorical_accuracy: 0.0263 - val_loss: 5.0936 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 4.7295 - categorical_accuracy: 0.0376 - val_loss: 5.0433 - val_categorical_accuracy: 0.0299 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 4.6791 - categorical_accuracy: 0.0376 - val_loss: 4.9875 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 4.6728 - categorical_accuracy: 0.0357 - val_loss: 5.0876 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 4.6342 - categorical_accuracy: 0.0244 - val_loss: 5.2044 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 4.5991 - categorical_accuracy: 0.0414 - val_loss: 5.1368 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 1s 75ms/step - loss: 4.5505 - categorical_accuracy: 0.0338 - val_loss: 4.9405 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 4.5477 - categorical_accuracy: 0.0320 - val_loss: 5.1822 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 4.5317 - categorical_accuracy: 0.0451 - val_loss: 4.9159 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 1s 71ms/step - loss: 4.5276 - categorical_accuracy: 0.0545 - val_loss: 4.8820 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 4.5097 - categorical_accuracy: 0.0451 - val_loss: 4.8819 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 4.4614 - categorical_accuracy: 0.0564 - val_loss: 5.1989 - val_categorical_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 4.4410 - categorical_accuracy: 0.0376 - val_loss: 5.0864 - val_categorical_accuracy: 0.0224 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 4.4565 - categorical_accuracy: 0.0301 - val_loss: 5.0005 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 1s 79ms/step - loss: 4.4595 - categorical_accuracy: 0.0376 - val_loss: 5.3430 - val_categorical_accuracy: 0.0075 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - ETA: 0s - loss: 4.4111 - categorical_accuracy: 0.0376\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "17/17 [==============================] - 1s 76ms/step - loss: 4.4111 - categorical_accuracy: 0.0376 - val_loss: 4.8994 - val_categorical_accuracy: 0.0149 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 4.3999 - categorical_accuracy: 0.0432 - val_loss: 4.9616 - val_categorical_accuracy: 0.0149 - lr: 2.0000e-04\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 1s 69ms/step - loss: 4.3766 - categorical_accuracy: 0.0414 - val_loss: 5.0659 - val_categorical_accuracy: 0.0224 - lr: 2.0000e-04\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 1s 79ms/step - loss: 4.3484 - categorical_accuracy: 0.0451 - val_loss: 4.9951 - val_categorical_accuracy: 0.0299 - lr: 2.0000e-04\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 1s 74ms/step - loss: 4.3540 - categorical_accuracy: 0.0470 - val_loss: 4.9939 - val_categorical_accuracy: 0.0075 - lr: 2.0000e-04\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - ETA: 0s - loss: 4.3344 - categorical_accuracy: 0.0357Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 4.3344 - categorical_accuracy: 0.0357 - val_loss: 5.2795 - val_categorical_accuracy: 0.0149 - lr: 2.0000e-04\n",
      "Epoch 54: early stopping\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000171E7960670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 531us/step\n",
      "Sequence 1: Predicted - bring, True - play\n",
      "Sequence 2: Predicted - day, True - city\n",
      "Sequence 3: Predicted - day, True - bad\n",
      "Sequence 4: Predicted - bring, True - what\n",
      "Sequence 5: Predicted - study, True - time\n",
      "Sequence 6: Predicted - computer, True - name\n",
      "Sequence 7: Predicted - day, True - study\n",
      "Sequence 8: Predicted - yes, True - who\n",
      "Sequence 9: Predicted - bring, True - we\n",
      "Sequence 10: Predicted - day, True - many\n",
      "Sequence 11: Predicted - bring, True - her\n",
      "Sequence 12: Predicted - bring, True - man\n",
      "Sequence 13: Predicted - computer, True - man\n",
      "Sequence 14: Predicted - bring, True - on\n",
      "Sequence 15: Predicted - computer, True - call\n",
      "Sequence 16: Predicted - bring, True - go\n",
      "Sequence 17: Predicted - yes, True - call\n",
      "Sequence 18: Predicted - mother, True - before\n",
      "Sequence 19: Predicted - yes, True - before\n",
      "Sequence 20: Predicted - bring, True - help\n",
      "Sequence 21: Predicted - day, True - no\n",
      "Sequence 22: Predicted - bring, True - right\n",
      "Sequence 23: Predicted - bring, True - many\n",
      "Sequence 24: Predicted - day, True - computer\n",
      "Sequence 25: Predicted - computer, True - mother\n",
      "Sequence 26: Predicted - day, True - get\n",
      "Sequence 27: Predicted - mother, True - before\n",
      "Sequence 28: Predicted - yes, True - what\n",
      "Sequence 29: Predicted - yes, True - where\n",
      "Sequence 30: Predicted - bring, True - when\n",
      "Sequence 31: Predicted - yes, True - home\n",
      "Sequence 32: Predicted - day, True - school\n",
      "Sequence 33: Predicted - bring, True - can\n",
      "Sequence 34: Predicted - bring, True - before\n",
      "Sequence 35: Predicted - bring, True - have\n",
      "Sequence 36: Predicted - yes, True - we\n",
      "Model saved to action4.h5\n"
     ]
    }
   ],
   "source": [
    "# 7. Build and Train LSTM Neural Network\n",
    "\n",
    "# Define the TensorBoard callback\n",
    "log_dir = os.path.join('Logs')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Get the number of classes (actions)\n",
    "num_classes = len(actions)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(sequence_length, X.shape[2])))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=500, callbacks=[tb_callback])\n",
    "\n",
    "# 8. Make Predictions\n",
    "\n",
    "# Make predictions on the test set\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# Convert predictions and true labels from one-hot encoding to label indices\n",
    "yhat_classes = np.argmax(yhat, axis=1)\n",
    "ytrue = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Map indices back to action labels\n",
    "predicted_actions = [actions[idx] for idx in yhat_classes]\n",
    "true_actions = [actions[idx] for idx in ytrue]\n",
    "\n",
    "# Compare predictions to true labels\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"Sequence {i+1}: Predicted - {predicted_actions[i]}, True - {true_actions[i]}\")\n",
    "\n",
    "# 9. Save Weights\n",
    "\n",
    "# Save the model\n",
    "model_save_path = 'action2.h5'\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 empty or corrupted .npy files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "actions = np.array(os.listdir(DATA_PATH))\n",
    "\n",
    "empty_files = []\n",
    "\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    sequences_dirs = os.listdir(action_path)\n",
    "    for sequence in sequences_dirs:\n",
    "        sequence_path = os.path.join(action_path, sequence)\n",
    "        frame_files = os.listdir(sequence_path)\n",
    "        for frame_file in frame_files:\n",
    "            file_path = os.path.join(sequence_path, frame_file)\n",
    "            try:\n",
    "                data = np.load(file_path)\n",
    "                if data.size == 0:\n",
    "                    empty_files.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "                empty_files.append(file_path)\n",
    "\n",
    "print(f\"Found {len(empty_files)} empty or corrupted .npy files.\")\n",
    "for file in empty_files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['about', 'after', 'again', 'all', 'animal', 'ask', 'baby', 'back',\n",
       "       'bad', 'because', 'bed', 'before', 'big', 'book', 'boy', 'bring',\n",
       "       'brother', 'buy', 'call', 'can', 'car', 'chair', 'child', 'city',\n",
       "       'clothes', 'come', 'computer', 'day', 'dog', 'drink', 'eat',\n",
       "       'family', 'father', 'find', 'first', 'friend', 'get', 'give', 'go',\n",
       "       'good', 'happy', 'have', 'help', 'her', 'home', 'hot', 'how',\n",
       "       'know', 'late', 'leave', 'like', 'make', 'man', 'many', 'me',\n",
       "       'mother', 'name', 'need', 'new', 'no', 'now', 'on', 'one', 'out',\n",
       "       'people', 'play', 'please', 'read', 'right', 'run', 'say',\n",
       "       'school', 'see', 'she', 'sit', 'sleep', 'small', 'sorry', 'stop',\n",
       "       'study', 'take', 'thank you', 'think', 'time', 'today', 'tomorrow',\n",
       "       'want', 'watch', 'we', 'what', 'when', 'where', 'who', 'why',\n",
       "       'work', 'yes', 'you'], dtype='<U9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
